import os
import time
import json
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard

# Reproducibility
os.environ["PYTHONHASHSEED"] = "42"
os.environ["TF_DETERMINISTIC_OPS"] = "1"
tf.random.set_seed(42)
np.random.seed(42)

try:
    tf.keras.mixed_precision.set_global_policy("mixed_float16")
    MIXED_PREC = True
except Exception:
    MIXED_PREC = False

# Config
IMG_HEIGHT, IMG_WIDTH = 240, 240
BATCH_SIZE = 32
EPOCHS = 50
LR = 1e-3

DATA_DIR = "Tumor_Type"        # Root dataset folder
TRAIN_DIR = os.path.join(DATA_DIR, "train")
VAL_DIR = os.path.join(DATA_DIR, "val")
TEST_DIR = os.path.join(DATA_DIR, "test")

OUT_DIR = "outputs"
os.makedirs(OUT_DIR, exist_ok=True)

# Data augmentation and generators
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.10,
    height_shift_range=0.10,
    zoom_range=0.10,
    horizontal_flip=True,
    fill_mode="nearest"
)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_directory(
    TRAIN_DIR,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    shuffle=True
)
val_gen = val_datagen.flow_from_directory(
    VAL_DIR,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    shuffle=False
)
test_gen = test_datagen.flow_from_directory(
    TEST_DIR,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    shuffle=False
)

class_names = list(train_gen.class_indices.keys())
num_classes = len(class_names)
with open(os.path.join(OUT_DIR, "class_indices.json"), "w") as f:
    json.dump(train_gen.class_indices, f, indent=2)

# Compute class weights for imbalance handling
def compute_class_weights(generator):
    cls_counts = np.bincount(generator.classes, minlength=num_classes)
    total = cls_counts.sum()
    weights = {i: (total / (num_classes * cls_counts[i])) for i in range(num_classes) if cls_counts[i] > 0}
    return weights, cls_counts

class_weights, train_counts = compute_class_weights(train_gen)
with open(os.path.join(OUT_DIR, "class_weights.json"), "w") as f:
    json.dump({class_names[i]: class_weights[i] for i in range(num_classes)}, f, indent=2)

# Build CNN model
def build_model():
    model = Sequential(name="BrainTumorCNN")
    model.add(Conv2D(32, (3,3), activation='relu', padding='same',
                     input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Dropout(0.25))

    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Dropout(0.25))

    model.add(Conv2D(128, (3,3), activation='relu', padding='same'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Dropout(0.25))

    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax', dtype='float32'))

    opt = Adam(learning_rate=LR)
    model.compile(optimizer=opt, loss="categorical_crossentropy", metrics=["accuracy"])
    return model

model = build_model()
model.summary()

# Callbacks
ckpt_path = os.path.join(OUT_DIR, "best_model.h5")
callbacks = [
    EarlyStopping(monitor="val_loss", patience=8, restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=4, min_lr=1e-6, verbose=1),
    ModelCheckpoint(ckpt_path, monitor="val_loss", save_best_only=True, verbose=1),
    TensorBoard(log_dir=os.path.join(OUT_DIR, "tb_logs"))
]

# Train model
history = model.fit(
    train_gen,
    epochs=EPOCHS,
    validation_data=val_gen,
    callbacks=callbacks,
    class_weight=class_weights,
    verbose=2
)

# Save final model
final_model_path = os.path.join(OUT_DIR, "model_final.h5")
model.save(final_model_path)
with open(os.path.join(OUT_DIR, "train_counts.json"), "w") as f:
    json.dump({class_names[i]: int(train_counts[i]) for i in range(num_classes)}, f, indent=2)

# Plot training curves (accuracy and loss saved as PNGs)
def plot_curves(hist, out_dir):
    plt.figure(figsize=(6,4))
    plt.plot(hist.history["accuracy"], label="Train Acc")
    plt.plot(hist.history["val_accuracy"], label="Val Acc")
    plt.xlabel("Epoch"); plt.ylabel("Accuracy"); plt.title("Accuracy vs. Epochs")
    plt.legend(); plt.grid(True, alpha=0.3)
    plt.tight_layout()
    acc_path = os.path.join(out_dir, "accuracy_curve.png")
    plt.savefig(acc_path, dpi=300)
    plt.close()

    plt.figure(figsize=(6,4))
    plt.plot(hist.history["loss"], label="Train Loss")
    plt.plot(hist.history["val_loss"], label="Val Loss")
    plt.xlabel("Epoch"); plt.ylabel("Loss"); plt.title("Loss vs. Epochs")
    plt.legend(); plt.grid(True, alpha=0.3)
    plt.tight_layout()
    loss_path = os.path.join(out_dir, "loss_curve.png")
    plt.savefig(loss_path, dpi=300)
    plt.close()
    return acc_path, loss_path

acc_png, loss_png = plot_curves(history, OUT_DIR)

# Evaluate model on test set
test_loss, test_acc = model.evaluate(test_gen, verbose=0)
print(f"[TEST] Loss: {test_loss:.4f} | Accuracy: {test_acc*100:.2f}%")

y_prob = model.predict(test_gen, verbose=0)
y_pred = np.argmax(y_prob, axis=1)
y_true = test_gen.classes

report = classification_report(y_true, y_pred, target_names=class_names, digits=3)
with open(os.path.join(OUT_DIR, "classification_report.txt"), "w") as f:
    f.write(report)
print(report)

# Plot Confusion Matrix
def plot_confusion(cm, labels, out_path, normalize=True):
    from matplotlib import cm as mplcm
    cmn = cm.astype("float")
    if normalize:
        cmn = cmn / cmn.sum(axis=1, keepdims=True)
    plt.figure(figsize=(5.2,4.5))
    plt.imshow(cmn, interpolation='nearest', cmap=mplcm.Blues)
    plt.title("Confusion Matrix")
    plt.colorbar()
    tick_marks = np.arange(len(labels))
    plt.xticks(tick_marks, labels, rotation=45, ha="right")
    plt.yticks(tick_marks, labels)
    thresh = cmn.max() / 2.
    for i in range(cmn.shape[0]):
        for j in range(cmn.shape[1]):
            val = cmn[i, j]
            txt = f"{val:.2f}" if normalize else f"{int(cm[i,j])}"
            plt.text(j, i, txt, horizontalalignment="center",
                     color="white" if val > thresh else "black")
    plt.ylabel('True label'); plt.xlabel('Predicted label')
    plt.tight_layout()
    plt.savefig(out_path, dpi=300)
    plt.close()

cm = confusion_matrix(y_true, y_pred)
plot_confusion(cm, class_names, os.path.join(OUT_DIR, "confusion_matrix.png"))

# Plot ROC and Precision-Recall curves
def plot_roc_pr(y_true_idx, y_prob, labels, out_dir):
    y_true_1h = tf.keras.utils.to_categorical(y_true_idx, num_classes=len(labels))

    plt.figure(figsize=(6,4))
    for i, lbl in enumerate(labels):
        fpr, tpr, _ = roc_curve(y_true_1h[:, i], y_prob[:, i])
        plt.plot(fpr, tpr, label=f"{lbl} (AUC={auc(fpr, tpr):.3f})")
    plt.plot([0,1], [0,1], 'k--', lw=1)
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curves (per class)")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(os.path.join(out_dir, "roc_curves.png"), dpi=300)
    plt.close()

    plt.figure(figsize=(6,4))
    for i, lbl in enumerate(labels):
        precision, recall, _ = precision_recall_curve(y_true_1h[:, i], y_prob[:, i])
        ap = auc(recall, precision)
        plt.plot(recall, precision, label=f"{lbl} (AP={ap:.3f})")
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.title("Precisionâ€“Recall Curves (per class)")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(os.path.join(out_dir, "pr_curves.png"), dpi=300)
    plt.close()

plot_roc_pr(y_true, y_prob, class_names, OUT_DIR)

print(f"\nArtifacts saved to: {OUT_DIR}")
print(f"Figures for LaTeX: {acc_png}, {loss_png}, confusion_matrix.png, roc_curves.png, pr_curves.png")
